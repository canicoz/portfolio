{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Plant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will try several machine learning tecniques to predict the outcome of a power plant, where the target variable is amount of power produced. I will first explore the data set, then apply several regression models. \n",
    "\n",
    "Before that, let's import necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Importing modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can read data and explore its properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of dataset is (7176, 5)\n",
      "\n",
      "Here is the summary statistics:\n",
      "\n",
      "                    power  feat1  feat2      feat3  feat4\n",
      "minimum             22.1  -23.2    6.3   985830.6   21.6\n",
      "median              23.8   -4.7   13.1  1025885.4   70.8\n",
      "maximum             26.1   12.1   20.1  1067708.9   96.2\n",
      "number of missing    0.0    0.0    1.0        6.0    4.0\n"
     ]
    }
   ],
   "source": [
    "## Reading data\n",
    "df=pd.read_csv(\"Data/data_power.csv\")\n",
    "\n",
    "## Calculating summary statistics\n",
    "def summary_stat (L):\n",
    "    \"\"\" this function returns summary statistics of each column in df\"\"\"\n",
    "    sum_stat=[]\n",
    "    sum_stat.append(np.nanmin(L.values))\n",
    "    sum_stat.append(np.nanmedian(L.values))\n",
    "    sum_stat.append(np.nanmax(L.values))\n",
    "    sum_stat.append(L.isnull().sum())\n",
    "    return sum_stat\n",
    "\n",
    "tab=np.empty([4,len(df.columns)]) #empty table for summary statistics, will be filled in the for loop below\n",
    "for i in range(len(df.columns)):\n",
    "        tab[:,i]=summary_stat(df.iloc[:,i])\n",
    "        \n",
    "sum_tab=pd.DataFrame(tab,index=['minimum','median','maximum','number of missing'],columns=df.columns) #table to dataframe\n",
    "\n",
    "sum_tab=round(sum_tab,1) #rounding numbers\n",
    "\n",
    "## Printing the table\n",
    "print(\"The shape of dataset is\",df.shape)\n",
    "print(\"\\nHere is the summary statistics:\\n\\n\",sum_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going through regression models, there are two things that we need to consider:\n",
    "- Feature3 is far bigger than the other three features in terms of size. So the data needs to be scaled.\n",
    "- All features except feature1 have missing values. So, I need to use missing data imputation.\n",
    "\n",
    "Due to these properties, I will use pipelines, which include imputation, scaler, and a model to fit. For all models, the following applies: \n",
    "- Missing values will be imputed with the mean of the corresponding column.\n",
    "- Features are standardized by removing the mean and scaling to unit variance (using StandardScaler()).\n",
    "- 5-fold cross-validation is used to tune model parameters.\n",
    "\n",
    "Let's divide our dataset into train (80%) and test (20%) subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Creating train and test data sets\n",
    "X=df.iloc[:,1:]\n",
    "y=df.iloc[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score in Decision Tree model is obtained with these parameters:\n",
      " {'tree__max_depth': 9, 'tree__min_samples_leaf': 2, 'tree__min_samples_split': 3}\n",
      "\n",
      "The score (negative mean squared error) on the test data set is -0.043\n"
     ]
    }
   ],
   "source": [
    "## Defining three steps for decision tree pipeline\n",
    "steps = [('imputation', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "         ('scaler',StandardScaler()),\n",
    "         ('tree', DecisionTreeRegressor())]\n",
    "\n",
    "pipeline = Pipeline(steps) # creating a pipeline\n",
    "\n",
    "## Defining sets of model parameters\n",
    "parameters= {'tree__max_depth':[3,6,9,12],\n",
    "             'tree__min_samples_split':[2,3], \n",
    "             'tree__min_samples_leaf':[1,2]\n",
    "             }\n",
    "\n",
    "## Cross-validation\n",
    "cv=GridSearchCV(pipeline, \n",
    "                param_grid=parameters,scoring='neg_mean_squared_error',\n",
    "                cv=5)\n",
    "\n",
    "\n",
    "cv.fit(X_train,y_train) # model fitting\n",
    "tree_score=round(cv.score(X_test,y_test),3) # getting score\n",
    "result_tree=('Decision Tree',cv.best_params_,tree_score) # will be used later\n",
    "\n",
    "## Printing result\n",
    "print(\"Best score in Decision Tree model is obtained with these parameters:\\n\",cv.best_params_)\n",
    "print(\"\\nThe score (negative mean squared error) on the test data set is\", tree_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score in KNN model is obtained with these parameters:\n",
      " {'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
      "\n",
      "The score (negative mean squared error) on the test data set is -0.038\n"
     ]
    }
   ],
   "source": [
    "## Defining three steps for KNN pipeline\n",
    "steps = [('imputation', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "         ('scaler',StandardScaler()),\n",
    "         ('knn', KNeighborsRegressor())]\n",
    "\n",
    "pipeline = Pipeline(steps) # creating a pipeline\n",
    "\n",
    "## Defining sets of model parameters\n",
    "parameters= {'knn__n_neighbors':[3,5,7,10,20],\n",
    "             'knn__weights':['uniform','distance']\n",
    "            }\n",
    "## Cross-validation\n",
    "cv=GridSearchCV(pipeline,param_grid=parameters,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                cv=5)\n",
    "\n",
    "cv.fit(X_train,y_train) # model fitting\n",
    "knn_score=round(cv.score(X_test,y_test),3) #getting score\n",
    "result_knn=('KNN',cv.best_params_,knn_score) #will be used later\n",
    "\n",
    "## Printing results\n",
    "print(\"Best score in KNN model is obtained with these parameters:\\n\",cv.best_params_)\n",
    "print(\"\\nThe score (negative mean squared error) on the test data set is\", knn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score in Elastic Net model is obtained with these parameters:\n",
      " {'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.1}\n",
      "\n",
      "The score (negative mean squared error) on the test data set is -0.066\n"
     ]
    }
   ],
   "source": [
    "## Defining three steps for ElasticNet pipeline\n",
    "steps = [('imputation', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('elasticnet', ElasticNet())]\n",
    "\n",
    "pipeline = Pipeline(steps) # creating a pipeline\n",
    "\n",
    "## Defining sets of model parameters\n",
    "parameters={'elasticnet__l1_ratio':np.linspace(0.1, 1, 5),\n",
    "           'elasticnet__alpha':np.linspace(0.1, 1, 5)\n",
    "           }\n",
    "\n",
    "## Cross-validation\n",
    "cv=GridSearchCV(pipeline,param_grid=parameters,\n",
    "                scoring='neg_mean_squared_error',\n",
    "                cv=5)\n",
    "\n",
    "cv.fit(X_train,y_train) # model fitting\n",
    "elastic_score=round(cv.score(X_test,y_test),3) #getting score\n",
    "\n",
    "## This part is for \"nice printing\" of model parameters' values. otherwise, print returns numbers with many decimals.\n",
    "## Since round() didn't work on dictionary values (which are type numpy.float64), I converted them to float.\n",
    "floats = [float(np_float) for np_float in list(cv.best_params_.values())]\n",
    "for k, v in cv.best_params_.items():\n",
    "    cv.best_params_[k] = floats[list(cv.best_params_).index(k)]\n",
    "    \n",
    "result_elastic=('Elastic Net',cv.best_params_,elastic_score) # will be used later\n",
    "\n",
    "## Printing results    \n",
    "print(\"Best score in Elastic Net model is obtained with these parameters:\\n\",cv.best_params_)\n",
    "print(\"\\nThe score (negative mean squared error) on the test data set is\", elastic_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting that best 'l1_ratio' and 'alpha' parameters are the minimum in their set. It may be the case that we can achieve better scores if we decrease any or both of these parameters furher.\n",
    "\n",
    "The parameter l1_ratio corresponds to alpha in the glmnet R package while alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio = 1 is the lasso penalty.\n",
    "\n",
    "The documentation of sklearn.linear_model.ElasticNet() states that \"currently, l1_ratio <= 0.01 is not reliable\". Actually, decreasing alpha to 0 (zero) makes elastic net model equivalent to an ordinary least squares. Therefore, it makes sense to try ordinary least squares and check whether it produces better result than elastic net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The score (negative mean squared error) on the test data set is -0.056\n"
     ]
    }
   ],
   "source": [
    "## Defining three steps for OLS pipeline\n",
    "steps = [('imputation', Imputer(missing_values='NaN', strategy='mean', axis=0)),\n",
    "         ('scaler', StandardScaler()),\n",
    "         ('linearreg', LinearRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps) #creating a pipeline\n",
    "\n",
    "pipeline.fit(X_train,y_train) #fitting model\n",
    "y_pred = pipeline.predict(X_test) #prediction\n",
    "neg_mse_linear = round(-(mean_squared_error(y_test, y_pred)),3) # getting score\n",
    "\n",
    "result_ols=('OLS',\"\",neg_mse_linear) #will be used later\n",
    "\n",
    "## Printing results\n",
    "print(\"\\nThe score (negative mean squared error) on the test data set is\", neg_mse_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that OLS produces better result than ElasticNet in the test data set. My observation on the best parameters of elastic net led me to try OLS, which then brought out a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a table to compare the results of four regressions above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the table that includes all results:\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Model</th>\n",
       "      <th>Best parameters chosen by 5-fold CV</th>\n",
       "      <th>Negative MSE (greater is better)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>{'tree__max_depth': 9, 'tree__min_samples_leaf': 2, 'tree__min_samples_split': 3}</td>\n",
       "      <td>-0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNN</td>\n",
       "      <td>{'knn__n_neighbors': 7, 'knn__weights': 'distance'}</td>\n",
       "      <td>-0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>{'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.1}</td>\n",
       "      <td>-0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OLS</td>\n",
       "      <td></td>\n",
       "      <td>-0.056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Therefore, the best result is achieved by KNN with model parameters as the following:\n",
      "\n",
      " {'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "labels=['Model','Best parameters chosen by 5-fold CV', 'Negative MSE (greater is better)'] # column names\n",
    "res_df=pd.DataFrame([result_tree,result_knn,result_elastic,result_ols],columns=labels) # creating a dataframe for results\n",
    "\n",
    "## Printing final table for all results\n",
    "\n",
    "print(\"Here is the table that includes all results:\\n\\n\")\n",
    "pd.set_option('display.max_colwidth', -1) # to display long strings\n",
    "display(HTML(res_df.to_html(index=False))) # to display without index\n",
    "best_model_index=list(res_df.iloc[:,2]).index(max(list(res_df.iloc[:,2]))) #getting index of the model with best result\n",
    "\n",
    "print(\"\\n\\nTherefore, the best result is achieved by\", res_df.iloc[best_model_index,0],\n",
    "      \"with model parameters as the following:\\n\\n\",res_df.iloc[best_model_index,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE END "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
